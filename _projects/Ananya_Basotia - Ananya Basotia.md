---
layout: projects/projects-individual
title: "Developing AI Safety Benchmarks and Databases in the Indian Context"
advisor: "Prof. Anirban Sen, Prof. Debayan Gupta, Prof. Aalok Thakkar"
students: "Ananya Basotia, Kashyap J"
abstract: "This project focuses on developing AI safety benchmarks and structured risk databases grounded in the Indian socio-technical context. It addresses the gap between global AI risk frameworks and local realities by systematically collecting, categorising, and analysing AI-related harms relevant to India, with particular emphasis on education and financial lending."
categories: ["Artificial Intelligence", "AI Safety"]
---

## Project Description

This capstone project addresses a critical gap in contemporary AI governance and evaluation: the lack of context-sensitive AI safety benchmarks tailored to the Indian socio-technical landscape. While global AI risk frameworks and benchmarks have advanced rapidly, they often fail to capture structural inequalities, linguistic diversity, infrastructural constraints, and socio-economic realities specific to India. This project responds to that gap by developing domain-specific AI safety risk databases and benchmarks that are grounded in Indian contexts, use cases, and public failure modes.

The core objective of the project is to systematically identify, categorise, and represent AI risks in a way that is both analytically rigorous and practically useful for researchers, policymakers, and practitioners. The work focuses on two high-impact domains—education and financial lending—where algorithmic systems increasingly shape access to opportunity, resources, and decision-making. By grounding the analysis in real-world deployments, public reports, policy documents, and documented failures, the project ensures that the resulting benchmarks reflect lived risks rather than hypothetical concerns.

Beyond documentation, the project aims to contribute conceptual clarity by constructing a unified AI safety risk ontology that captures causal mechanisms, points of failure, and downstream harms. This enables more consistent evaluation of AI systems and supports comparative analysis across domains. The resulting benchmarks are designed to support model evaluation, auditing, and future research on fairness, bias, and safety in Indian AI deployments.

## Methodology

The project follows a mixed-methods research approach combining qualitative analysis, literature review, and dataset construction. First, AI risk examples were collected from academic literature, policy reports, media investigations, and documented public failures relevant to the Indian context. These examples were then categorised into domain-specific risk taxonomies for education and financial lending.

Next, the project developed structured AI safety risk databases that encode each risk along dimensions such as domain, stakeholder, causal factor, and type of harm. A unified ontology was constructed to link these risks across domains and to explicitly model causal pathways. For the education domain, a dedicated bias benchmark was developed, including dataset design and implementation details to enable systematic evaluation of model behaviour.

## Outcomes and Contributions

Key contributions of this project include domain-specific AI risk taxonomies, a unified AI safety risk ontology, and an education-focused bias benchmark tailored to India. Together, these outputs provide foundational infrastructure for evaluating AI systems beyond generic benchmarks, enabling more responsible and context-aware AI development and governance.
